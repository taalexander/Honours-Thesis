% Chapter 5

\chapter{Discussion and Conclusion} % Write in your own chapter title
\label{Chapter5}
\lhead{Chapter 5. \emph{Discussion and Conclusion}} % Write in your own chapter title to set the page header

\section{Results}
While it was not possible to carry out our proposed experiment to test the algorithm described in section (\ref{sec:robusthamiltonian}) it was still possible to model and simulate the behaviour of the algorithm for the proposed system. Our model model attempted to take into account imperfections in the experimental setup such as variable offsets, temperatures, humidities, and phase constants. The derived model for probability of detection at the O-detector is given by (\ref{eq:finalmodel}).

Simulation of the behaviour of the MCMC algorithm was performed on a variety of chosen parameter sets for the model in order to verify if in theory the algorithm would be able to adequately converge on a valid approximate solution. Simulations demonstrated that the algorithm would be able to greatly decrease the Bayes risk and converge on the true parameter set in all tested cases.   

The most interesting aspect of the algorithm and our results is that of experimental design. The Robust Online Hamiltonian Learning algorithm allows future experimental parameters to be chosen to maximize the amount of information gain and thus reduce the Bayes risk to a much greater degree with each additional experiment. This is especially useful when experiments require a long time to perform for different experimental parameters and the time of simulation is much less than that of performing additional experiments. As could be seen in fig(\ref{fig:adaptivetimes}) the algorithm could rapidly converge on the true parameter set in as little as $50$ experiments, rivalling the accuracy of the naive test of $2^15$ phase flag settings experiment. Analysis of the probability density functions, shows that the majority of probability density is concentrated around the true values of parameters. 

A downside of the experimental adaptive design is the simulation time required greatly increases. The selection of experimental parameters to maximize information gain greatly increases the computational time. Therefore adaptive experimental design will only actually increase the average information gain per time unit if the cost of simulation is less than the time taken to perform enough experiments to equal the information gained through measurement of choice experimental parameters. In section (\ref{sec:gpu}) we explored implementing the likelihood functions on graphics processing units for GPGPU calculations. Although the speed-up experienced was lower than expected, there are almost certainly large optimizations to be made as our approach was relatively naive and experimental. Additional ways in which the likelihood evaluation speed could be increased is through field programmable gate arrays or application specific circuits (ASIC). 

\section{Ni-Engine}
Ni-Engine was programmed to be compatible with Q-Infer in order to perform the experimental verification of our simulations. Unfortunately due to scheduling conflicts and the priorities of the research group, both Q-Infer and Ni-Engine have to yet to be put to use at NIST. However, it is anticipated that at some point in the near future, the software and hardware will be installed and we will be able to perform our experimental verification. 

Ni-Engine was extensively tested at IQC with the real hardware. While, experiments were not able to be performed at the neutron interferometry lab, simulated experiments were performed with backups of the lab equipment. This allowed real experiments to be scripted, data measured and stored. This, along with the thorough documentation provided, allows me to believe that Ni-Engine will have widespread use in the lab when installed due to the benefits it provides over the current experimental system. 

\section{Application to Quantum Information and Fundamentals}
The algorithm implemented by Q-Infer has the potential to be very useful in the field of experimental quantum mechanics. Most quantum experimental setups in existence have been modelled mathematically, however all models require that the parameters of the particulars of the system be discovered. This is normally a very experimentally and computationally challenging task as many experiments must be done to gain sufficient information to fit the parameters to the system and fitting itself is a computationally intensive task. Our algorithm solves this issue and, even though it is using approximate probabilistic methods, allows the error in approximated parameters to be calculated. The amount of experiments required with this algorithm are often much less than would be required to characterise the system with quantum tomography. Provided the system has a model the proposed algorithm appears to be an excellent solution to the problem of discovering system parameters. 


